{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card/binding_values/broadcast_height/string_value</th>\n",
       "      <th>card/binding_values/broadcast_height/type</th>\n",
       "      <th>card/binding_values/broadcast_id/string_value</th>\n",
       "      <th>card/binding_values/broadcast_id/type</th>\n",
       "      <th>card/binding_values/broadcast_is_high_latency/boolean_value</th>\n",
       "      <th>card/binding_values/broadcast_is_high_latency/type</th>\n",
       "      <th>card/binding_values/broadcast_media_id/string_value</th>\n",
       "      <th>card/binding_values/broadcast_media_id/type</th>\n",
       "      <th>card/binding_values/broadcast_media_key/string_value</th>\n",
       "      <th>card/binding_values/broadcast_media_key/type</th>\n",
       "      <th>...</th>\n",
       "      <th>user/screen_name</th>\n",
       "      <th>user/show_all_inline_media</th>\n",
       "      <th>user/statuses_count</th>\n",
       "      <th>user/time_zone</th>\n",
       "      <th>user/translator_type</th>\n",
       "      <th>user/url</th>\n",
       "      <th>user/utc_offset</th>\n",
       "      <th>user/verified</th>\n",
       "      <th>user/verified_type</th>\n",
       "      <th>user/withheld_scope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>720.0</td>\n",
       "      <td>STRING</td>\n",
       "      <td>1OdKrXLYAXVJX</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>BOOLEAN</td>\n",
       "      <td>1.866126e+18</td>\n",
       "      <td>STRING</td>\n",
       "      <td>28_1866126037895262208</td>\n",
       "      <td>STRING</td>\n",
       "      <td>...</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>18658.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>https://t.co/X1EgXc8I5w</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Government</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>18658.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>https://t.co/X1EgXc8I5w</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Government</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>18658.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>https://t.co/X1EgXc8I5w</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Government</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1544 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   card/binding_values/broadcast_height/string_value  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                              720.0   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "  card/binding_values/broadcast_height/type  \\\n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                    STRING   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "\n",
       "  card/binding_values/broadcast_id/string_value  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2                                 1OdKrXLYAXVJX   \n",
       "3                                           NaN   \n",
       "4                                           NaN   \n",
       "\n",
       "  card/binding_values/broadcast_id/type  \\\n",
       "0                                   NaN   \n",
       "1                                   NaN   \n",
       "2                                STRING   \n",
       "3                                   NaN   \n",
       "4                                   NaN   \n",
       "\n",
       "  card/binding_values/broadcast_is_high_latency/boolean_value  \\\n",
       "0                                                NaN            \n",
       "1                                                NaN            \n",
       "2                                               True            \n",
       "3                                                NaN            \n",
       "4                                                NaN            \n",
       "\n",
       "  card/binding_values/broadcast_is_high_latency/type  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                            BOOLEAN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "   card/binding_values/broadcast_media_id/string_value  \\\n",
       "0                                                NaN     \n",
       "1                                                NaN     \n",
       "2                                       1.866126e+18     \n",
       "3                                                NaN     \n",
       "4                                                NaN     \n",
       "\n",
       "  card/binding_values/broadcast_media_id/type  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                      STRING   \n",
       "3                                         NaN   \n",
       "4                                         NaN   \n",
       "\n",
       "  card/binding_values/broadcast_media_key/string_value  \\\n",
       "0                                                NaN     \n",
       "1                                                NaN     \n",
       "2                             28_1866126037895262208     \n",
       "3                                                NaN     \n",
       "4                                                NaN     \n",
       "\n",
       "  card/binding_values/broadcast_media_key/type  ...  user/screen_name  \\\n",
       "0                                          NaN  ...               NaN   \n",
       "1                                          NaN  ...               NaN   \n",
       "2                                       STRING  ...      WilliamsRuto   \n",
       "3                                          NaN  ...      WilliamsRuto   \n",
       "4                                          NaN  ...      WilliamsRuto   \n",
       "\n",
       "  user/show_all_inline_media user/statuses_count user/time_zone  \\\n",
       "0                        NaN                 NaN            NaN   \n",
       "1                        NaN                 NaN            NaN   \n",
       "2                      False             18658.0            NaN   \n",
       "3                      False             18658.0            NaN   \n",
       "4                      False             18658.0            NaN   \n",
       "\n",
       "  user/translator_type                 user/url  user/utc_offset  \\\n",
       "0                  NaN                      NaN              NaN   \n",
       "1                  NaN                      NaN              NaN   \n",
       "2                 none  https://t.co/X1EgXc8I5w              0.0   \n",
       "3                 none  https://t.co/X1EgXc8I5w              0.0   \n",
       "4                 none  https://t.co/X1EgXc8I5w              0.0   \n",
       "\n",
       "  user/verified  user/verified_type user/withheld_scope  \n",
       "0           NaN                 NaN                 NaN  \n",
       "1           NaN                 NaN                 NaN  \n",
       "2         False          Government                 NaN  \n",
       "3         False          Government                 NaN  \n",
       "4         False          Government                 NaN  \n",
       "\n",
       "[5 rows x 1544 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tweets=pd.read_csv(r\"E:\\Python\\Sentiment Analysis\\zote.csv\")\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.dropna(subset=['user/name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['card/binding_values/broadcast_height/string_value',\n",
       "       'card/binding_values/broadcast_height/type',\n",
       "       'card/binding_values/broadcast_id/string_value',\n",
       "       'card/binding_values/broadcast_id/type',\n",
       "       'card/binding_values/broadcast_is_high_latency/boolean_value',\n",
       "       'card/binding_values/broadcast_is_high_latency/type',\n",
       "       'card/binding_values/broadcast_media_id/string_value',\n",
       "       'card/binding_values/broadcast_media_id/type',\n",
       "       'card/binding_values/broadcast_media_key/string_value',\n",
       "       'card/binding_values/broadcast_media_key/type',\n",
       "       ...\n",
       "       'user/screen_name', 'user/show_all_inline_media', 'user/statuses_count',\n",
       "       'user/time_zone', 'user/translator_type', 'user/url', 'user/utc_offset',\n",
       "       'user/verified', 'user/verified_type', 'user/withheld_scope'],\n",
       "      dtype='object', length=1544)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check columns of the scraped tweets\n",
    "tweets=pd.DataFrame(tweets)\n",
    "tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user/name</th>\n",
       "      <th>user/screen_name</th>\n",
       "      <th>user/verified</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>Hustler Fund 2nd Anniversary, KICC, Nairobi. h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>I have had a fruitful engagement with Retired ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>Kenya and the US signed the Washington-Nairobi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>Kenya and the International Monetary Fund (IMF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>Your Excellency and Dear Mr. President-Elect,â€‹...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>khalif kairo</td>\n",
       "      <td>KhalifKairo</td>\n",
       "      <td>False</td>\n",
       "      <td>Mm sizimi simu, saa hii niko kwa jam apa Ngara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>khalif kairo</td>\n",
       "      <td>KhalifKairo</td>\n",
       "      <td>False</td>\n",
       "      <td>Clearly this is a man who is used to killing, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>khalif kairo</td>\n",
       "      <td>KhalifKairo</td>\n",
       "      <td>False</td>\n",
       "      <td>Hate to be the NIS/DCI guy assigned to tail me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>khalif kairo</td>\n",
       "      <td>KhalifKairo</td>\n",
       "      <td>False</td>\n",
       "      <td>We are formatting this country.\\nGoing forward...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>khalif kairo</td>\n",
       "      <td>KhalifKairo</td>\n",
       "      <td>False</td>\n",
       "      <td>GIVE YOUR TWITTER ACCOUNT TO PEOPLE YOU TRUST....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    user/name user/screen_name user/verified  \\\n",
       "2    William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "3    William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "4    William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "5    William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "6    William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "..                        ...              ...           ...   \n",
       "156              khalif kairo      KhalifKairo         False   \n",
       "157              khalif kairo      KhalifKairo         False   \n",
       "158              khalif kairo      KhalifKairo         False   \n",
       "159              khalif kairo      KhalifKairo         False   \n",
       "160              khalif kairo      KhalifKairo         False   \n",
       "\n",
       "                                             full_text  \n",
       "2    Hustler Fund 2nd Anniversary, KICC, Nairobi. h...  \n",
       "3    I have had a fruitful engagement with Retired ...  \n",
       "4    Kenya and the US signed the Washington-Nairobi...  \n",
       "5    Kenya and the International Monetary Fund (IMF...  \n",
       "6    Your Excellency and Dear Mr. President-Elect,â€‹...  \n",
       "..                                                 ...  \n",
       "156  Mm sizimi simu, saa hii niko kwa jam apa Ngara...  \n",
       "157  Clearly this is a man who is used to killing, ...  \n",
       "158  Hate to be the NIS/DCI guy assigned to tail me...  \n",
       "159  We are formatting this country.\\nGoing forward...  \n",
       "160  GIVE YOUR TWITTER ACCOUNT TO PEOPLE YOU TRUST....  \n",
       "\n",
       "[158 rows x 4 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping unnecessary columns\n",
    "columns_to_keep = ['user/name', 'user/screen_name', 'user/verified','full_text']\n",
    "\n",
    "# Keep only the selected columns\n",
    "cleaned_tweets = tweets[columns_to_keep]\n",
    "\n",
    "\n",
    "cleaned_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tokenisation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      [Hustler, Fund, 2nd, Anniversary, ,, KICC, ,, ...\n",
       "3      [I, have, had, a, fruitful, engagement, with, ...\n",
       "4      [Kenya, and, the, US, signed, the, Washington-...\n",
       "5      [Kenya, and, the, International, Monetary, Fun...\n",
       "6      [Your, Excellency, and, Dear, Mr., President-E...\n",
       "                             ...                        \n",
       "156    [Mm, sizimi, simu, ,, saa, hii, niko, kwa, jam...\n",
       "157    [Clearly, this, is, a, man, who, is, used, to,...\n",
       "158    [Hate, to, be, the, NIS/DCI, guy, assigned, to...\n",
       "159    [We, are, formatting, this, country, ., Going,...\n",
       "160    [GIVE, YOUR, TWITTER, ACCOUNT, TO, PEOPLE, YOU...\n",
       "Name: tokens, Length: 158, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenising the full_text in a new colum\n",
    "df['tokens']=df['full_text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "df['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Original Text:',\n",
       " \"#STATEMENT\\n\\nThe Jurisprudence of Punishment, whether enforced by the State, Parents or Institutions- Is never out of Hate\\n\\nIt's Meant as a Deterrent and Rehabilitation \\n\\nHowever, Punishment should be a consequence of an iniquity, a crime... In tandem with the deed\\n\\nBut when aâ€¦ https://t.co/DEorjHJorS\")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the original tweet \n",
    "\"Original Text:\", df['full_text'].iloc[58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Tokenized Text:',\n",
       " ['#',\n",
       "  'STATEMENT',\n",
       "  'The',\n",
       "  'Jurisprudence',\n",
       "  'of',\n",
       "  'Punishment',\n",
       "  ',',\n",
       "  'whether',\n",
       "  'enforced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'State',\n",
       "  ',',\n",
       "  'Parents',\n",
       "  'or',\n",
       "  'Institutions-',\n",
       "  'Is',\n",
       "  'never',\n",
       "  'out',\n",
       "  'of',\n",
       "  'Hate',\n",
       "  'It',\n",
       "  \"'s\",\n",
       "  'Meant',\n",
       "  'as',\n",
       "  'a',\n",
       "  'Deterrent',\n",
       "  'and',\n",
       "  'Rehabilitation',\n",
       "  'However',\n",
       "  ',',\n",
       "  'Punishment',\n",
       "  'should',\n",
       "  'be',\n",
       "  'a',\n",
       "  'consequence',\n",
       "  'of',\n",
       "  'an',\n",
       "  'iniquity',\n",
       "  ',',\n",
       "  'a',\n",
       "  'crime',\n",
       "  '...',\n",
       "  'In',\n",
       "  'tandem',\n",
       "  'with',\n",
       "  'the',\n",
       "  'deed',\n",
       "  'But',\n",
       "  'when',\n",
       "  'aâ€¦',\n",
       "  'https',\n",
       "  ':',\n",
       "  '//t.co/DEorjHJorS'])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the tokenised tweet\n",
    "\n",
    "\"Tokenized Text:\", df['tokens'].iloc[58]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Lemmatisation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rono\\AppData\\Local\\Temp\\ipykernel_12324\\3360643037.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_tweets['Lemmatised'] = cleaned_tweets['full_text'].apply(lemma)\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "#load the nlp spacy english model\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "\n",
    "def lemma(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc if token.text not in STOP_WORDS]\n",
    "\n",
    "cleaned_tweets['Lemmatised'] = cleaned_tweets['full_text'].apply(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user/name</th>\n",
       "      <th>user/screen_name</th>\n",
       "      <th>user/verified</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Lemmatised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>Hustler Fund 2nd Anniversary, KICC, Nairobi. h...</td>\n",
       "      <td>[Hustler, Fund, 2nd, Anniversary, ,, KICC, ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>I have had a fruitful engagement with Retired ...</td>\n",
       "      <td>[I, fruitful, engagement, retired, President, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>Kenya and the US signed the Washington-Nairobi...</td>\n",
       "      <td>[Kenya, US, sign, Washington, -, Nairobi, Visi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>Kenya and the International Monetary Fund (IMF...</td>\n",
       "      <td>[Kenya, International, Monetary, Fund, (, IMF,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>Your Excellency and Dear Mr. President-Elect,â€‹...</td>\n",
       "      <td>[your, Excellency, Dear, Mr., President, -, El...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user/name user/screen_name user/verified  \\\n",
       "2  William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "3  William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "4  William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "5  William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "6  William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "\n",
       "                                           full_text  \\\n",
       "2  Hustler Fund 2nd Anniversary, KICC, Nairobi. h...   \n",
       "3  I have had a fruitful engagement with Retired ...   \n",
       "4  Kenya and the US signed the Washington-Nairobi...   \n",
       "5  Kenya and the International Monetary Fund (IMF...   \n",
       "6  Your Excellency and Dear Mr. President-Elect,â€‹...   \n",
       "\n",
       "                                          Lemmatised  \n",
       "2  [Hustler, Fund, 2nd, Anniversary, ,, KICC, ,, ...  \n",
       "3  [I, fruitful, engagement, retired, President, ...  \n",
       "4  [Kenya, US, sign, Washington, -, Nairobi, Visi...  \n",
       "5  [Kenya, International, Monetary, Fund, (, IMF,...  \n",
       "6  [your, Excellency, Dear, Mr., President, -, El...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_tweets.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#STATEMENT\\n\\nThe Jurisprudence of Punishment, whether enforced by the State, Parents or Institutions- Is never out of Hate\\n\\nIt's Meant as a Deterrent and Rehabilitation \\n\\nHowever, Punishment should be a consequence of an iniquity, a crime... In tandem with the deed\\n\\nBut when aâ€¦ https://t.co/DEorjHJorS\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check original tweet\n",
    "cleaned_tweets['full_text'].iloc[58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#',\n",
       " 'STATEMENT',\n",
       " '\\n\\n',\n",
       " 'the',\n",
       " 'jurisprudence',\n",
       " 'Punishment',\n",
       " ',',\n",
       " 'enforce',\n",
       " 'State',\n",
       " ',',\n",
       " 'Parents',\n",
       " 'Institutions-',\n",
       " 'be',\n",
       " 'Hate',\n",
       " '\\n\\n',\n",
       " 'it',\n",
       " 'mean',\n",
       " 'Deterrent',\n",
       " 'Rehabilitation',\n",
       " '\\n\\n',\n",
       " 'however',\n",
       " ',',\n",
       " 'Punishment',\n",
       " 'consequence',\n",
       " 'iniquity',\n",
       " ',',\n",
       " 'crime',\n",
       " '...',\n",
       " 'in',\n",
       " 'tandem',\n",
       " 'deed',\n",
       " '\\n\\n',\n",
       " 'but',\n",
       " 'â€¦',\n",
       " 'https://t.co/deorjhjors']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatised link\n",
    "cleaned_tweets['Lemmatised'].iloc[58]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Stemming</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rono\\AppData\\Local\\Temp\\ipykernel_12324\\383568934.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['stemed']=df_filtered['full_text'].apply(stemmer_)\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer=PorterStemmer()\n",
    "\n",
    "#stemming function\n",
    "def stemmer_(text):\n",
    "    return [stemmer.stem(word) for word in nltk.word_tokenize(text)]\n",
    "\n",
    "cleaned_tweets['stemed']=cleaned_tweets['full_text'].apply(stemmer_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user/name</th>\n",
       "      <th>user/screen_name</th>\n",
       "      <th>user/verified</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Lemmatised</th>\n",
       "      <th>stemed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>Hustler Fund 2nd Anniversary, KICC, Nairobi. h...</td>\n",
       "      <td>[Hustler, Fund, 2nd, Anniversary, ,, KICC, ,, ...</td>\n",
       "      <td>[hustler, fund, 2nd, anniversari, ,, kicc, ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>I have had a fruitful engagement with Retired ...</td>\n",
       "      <td>[I, fruitful, engagement, retired, President, ...</td>\n",
       "      <td>[i, have, had, a, fruit, engag, with, retir, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>Kenya and the US signed the Washington-Nairobi...</td>\n",
       "      <td>[Kenya, US, sign, Washington, -, Nairobi, Visi...</td>\n",
       "      <td>[kenya, and, the, us, sign, the, washington-na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>Kenya and the International Monetary Fund (IMF...</td>\n",
       "      <td>[Kenya, International, Monetary, Fund, (, IMF,...</td>\n",
       "      <td>[kenya, and, the, intern, monetari, fund, (, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>Your Excellency and Dear Mr. President-Elect,â€‹...</td>\n",
       "      <td>[your, Excellency, Dear, Mr., President, -, El...</td>\n",
       "      <td>[your, excel, and, dear, mr., president-elect,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>khalif kairo</td>\n",
       "      <td>KhalifKairo</td>\n",
       "      <td>False</td>\n",
       "      <td>Mm sizimi simu, saa hii niko kwa jam apa Ngara...</td>\n",
       "      <td>[mm, sizimi, simu, ,, saa, hii, niko, kwa, jam...</td>\n",
       "      <td>[mm, sizimi, simu, ,, saa, hii, niko, kwa, jam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>khalif kairo</td>\n",
       "      <td>KhalifKairo</td>\n",
       "      <td>False</td>\n",
       "      <td>Clearly this is a man who is used to killing, ...</td>\n",
       "      <td>[clearly, man, kill, ,, buy, intimidate, peopl...</td>\n",
       "      <td>[clearli, thi, is, a, man, who, is, use, to, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>khalif kairo</td>\n",
       "      <td>KhalifKairo</td>\n",
       "      <td>False</td>\n",
       "      <td>Hate to be the NIS/DCI guy assigned to tail me...</td>\n",
       "      <td>[hate, NIS, /, DCI, guy, assign, tail, old, un...</td>\n",
       "      <td>[hate, to, be, the, nis/dci, guy, assign, to, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>khalif kairo</td>\n",
       "      <td>KhalifKairo</td>\n",
       "      <td>False</td>\n",
       "      <td>We are formatting this country.\\nGoing forward...</td>\n",
       "      <td>[we, format, country, ., \\n, go, forward, ,, s...</td>\n",
       "      <td>[we, are, format, thi, countri, ., go, forward...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>khalif kairo</td>\n",
       "      <td>KhalifKairo</td>\n",
       "      <td>False</td>\n",
       "      <td>GIVE YOUR TWITTER ACCOUNT TO PEOPLE YOU TRUST....</td>\n",
       "      <td>[give, your, twitter, account, to, PEOPLE, you...</td>\n",
       "      <td>[give, your, twitter, account, to, peopl, you,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    user/name user/screen_name user/verified  \\\n",
       "2    William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "3    William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "4    William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "5    William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "6    William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "..                        ...              ...           ...   \n",
       "156              khalif kairo      KhalifKairo         False   \n",
       "157              khalif kairo      KhalifKairo         False   \n",
       "158              khalif kairo      KhalifKairo         False   \n",
       "159              khalif kairo      KhalifKairo         False   \n",
       "160              khalif kairo      KhalifKairo         False   \n",
       "\n",
       "                                             full_text  \\\n",
       "2    Hustler Fund 2nd Anniversary, KICC, Nairobi. h...   \n",
       "3    I have had a fruitful engagement with Retired ...   \n",
       "4    Kenya and the US signed the Washington-Nairobi...   \n",
       "5    Kenya and the International Monetary Fund (IMF...   \n",
       "6    Your Excellency and Dear Mr. President-Elect,â€‹...   \n",
       "..                                                 ...   \n",
       "156  Mm sizimi simu, saa hii niko kwa jam apa Ngara...   \n",
       "157  Clearly this is a man who is used to killing, ...   \n",
       "158  Hate to be the NIS/DCI guy assigned to tail me...   \n",
       "159  We are formatting this country.\\nGoing forward...   \n",
       "160  GIVE YOUR TWITTER ACCOUNT TO PEOPLE YOU TRUST....   \n",
       "\n",
       "                                            Lemmatised  \\\n",
       "2    [Hustler, Fund, 2nd, Anniversary, ,, KICC, ,, ...   \n",
       "3    [I, fruitful, engagement, retired, President, ...   \n",
       "4    [Kenya, US, sign, Washington, -, Nairobi, Visi...   \n",
       "5    [Kenya, International, Monetary, Fund, (, IMF,...   \n",
       "6    [your, Excellency, Dear, Mr., President, -, El...   \n",
       "..                                                 ...   \n",
       "156  [mm, sizimi, simu, ,, saa, hii, niko, kwa, jam...   \n",
       "157  [clearly, man, kill, ,, buy, intimidate, peopl...   \n",
       "158  [hate, NIS, /, DCI, guy, assign, tail, old, un...   \n",
       "159  [we, format, country, ., \\n, go, forward, ,, s...   \n",
       "160  [give, your, twitter, account, to, PEOPLE, you...   \n",
       "\n",
       "                                                stemed  \n",
       "2    [hustler, fund, 2nd, anniversari, ,, kicc, ,, ...  \n",
       "3    [i, have, had, a, fruit, engag, with, retir, p...  \n",
       "4    [kenya, and, the, us, sign, the, washington-na...  \n",
       "5    [kenya, and, the, intern, monetari, fund, (, i...  \n",
       "6    [your, excel, and, dear, mr., president-elect,...  \n",
       "..                                                 ...  \n",
       "156  [mm, sizimi, simu, ,, saa, hii, niko, kwa, jam...  \n",
       "157  [clearli, thi, is, a, man, who, is, use, to, k...  \n",
       "158  [hate, to, be, the, nis/dci, guy, assign, to, ...  \n",
       "159  [we, are, format, thi, countri, ., go, forward...  \n",
       "160  [give, your, twitter, account, to, peopl, you,...  \n",
       "\n",
       "[158 rows x 6 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chack the dataframe\n",
    "cleaned_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accessing specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['robert',\n",
       " 'lewandowski',\n",
       " 'to',\n",
       " 'barcelona',\n",
       " ',',\n",
       " 'here',\n",
       " 'we',\n",
       " 'go',\n",
       " '!',\n",
       " 'fc',\n",
       " 'bayern',\n",
       " 'have',\n",
       " 'just',\n",
       " 'told',\n",
       " 'barÃ§a',\n",
       " 'that',\n",
       " 'they',\n",
       " 'have',\n",
       " 'accept',\n",
       " 'final',\n",
       " 'propos',\n",
       " '.',\n",
       " 'agreement',\n",
       " 'final',\n",
       " 'in',\n",
       " 'place',\n",
       " 'between',\n",
       " 'all',\n",
       " 'parti',\n",
       " '.',\n",
       " 'ðŸš¨ðŸ”µðŸ”´',\n",
       " '#',\n",
       " 'fcb',\n",
       " 'lewandowski',\n",
       " 'ask',\n",
       " 'bayern',\n",
       " 'to',\n",
       " 'leav',\n",
       " 'also',\n",
       " 'on',\n",
       " 'friday',\n",
       " '-',\n",
       " 'he',\n",
       " 'will',\n",
       " 'jlin',\n",
       " 'barcelona',\n",
       " 'dure',\n",
       " 'the',\n",
       " 'weekend',\n",
       " '.',\n",
       " 'ðŸ‡µðŸ‡±',\n",
       " 'http',\n",
       " ':',\n",
       " '//t.co/nmodhunscw']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_tweets['stemed'].iloc[90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>post tagging</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rono\\AppData\\Local\\Temp\\ipykernel_12324\\65225300.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_tweets['pos_tags'] = cleaned_tweets['full_text'].apply(pos_tagging)\n"
     ]
    }
   ],
   "source": [
    "# post tagging function\n",
    "def pos_tagging(text):\n",
    "    doc = nlp(text)\n",
    "    return [(token.text, token.pos_) for token in doc]\n",
    "\n",
    "# Apply POS tagging and store in a new column\n",
    "cleaned_tweets['pos_tags'] = cleaned_tweets['full_text'].apply(pos_tagging)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hustler Fund 2nd Anniversary, KICC, Nairobi. h...</td>\n",
       "      <td>[(Hustler, PROPN), (Fund, PROPN), (2nd, PROPN)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have had a fruitful engagement with Retired ...</td>\n",
       "      <td>[(I, PRON), (have, AUX), (had, VERB), (a, DET)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kenya and the US signed the Washington-Nairobi...</td>\n",
       "      <td>[(Kenya, PROPN), (and, CCONJ), (the, DET), (US...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kenya and the International Monetary Fund (IMF...</td>\n",
       "      <td>[(Kenya, PROPN), (and, CCONJ), (the, DET), (In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Your Excellency and Dear Mr. President-Elect,â€‹...</td>\n",
       "      <td>[(Your, PRON), (Excellency, PROPN), (and, CCON...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "2  Hustler Fund 2nd Anniversary, KICC, Nairobi. h...   \n",
       "3  I have had a fruitful engagement with Retired ...   \n",
       "4  Kenya and the US signed the Washington-Nairobi...   \n",
       "5  Kenya and the International Monetary Fund (IMF...   \n",
       "6  Your Excellency and Dear Mr. President-Elect,â€‹...   \n",
       "\n",
       "                                            pos_tags  \n",
       "2  [(Hustler, PROPN), (Fund, PROPN), (2nd, PROPN)...  \n",
       "3  [(I, PRON), (have, AUX), (had, VERB), (a, DET)...  \n",
       "4  [(Kenya, PROPN), (and, CCONJ), (the, DET), (US...  \n",
       "5  [(Kenya, PROPN), (and, CCONJ), (the, DET), (In...  \n",
       "6  [(Your, PRON), (Excellency, PROPN), (and, CCON...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Display a sample of the POS tagged data\n",
    "(cleaned_tweets[['full_text', 'pos_tags']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rono\\AppData\\Local\\Temp\\ipykernel_12324\\2306147604.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_tweets['dependency_parsing'] = cleaned_tweets['full_text'].apply(dependency_parsing)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>dependency_parsing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hustler Fund 2nd Anniversary, KICC, Nairobi. h...</td>\n",
       "      <td>[(Hustler, compound, Fund), (Fund, compound, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have had a fruitful engagement with Retired ...</td>\n",
       "      <td>[(I, nsubj, had), (have, aux, had), (had, ROOT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kenya and the US signed the Washington-Nairobi...</td>\n",
       "      <td>[(Kenya, nsubj, signed), (and, cc, Kenya), (th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kenya and the International Monetary Fund (IMF...</td>\n",
       "      <td>[(Kenya, nsubj, have), (and, cc, Kenya), (the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Your Excellency and Dear Mr. President-Elect,â€‹...</td>\n",
       "      <td>[(Your, poss, Excellency), (Excellency, dep, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "2  Hustler Fund 2nd Anniversary, KICC, Nairobi. h...   \n",
       "3  I have had a fruitful engagement with Retired ...   \n",
       "4  Kenya and the US signed the Washington-Nairobi...   \n",
       "5  Kenya and the International Monetary Fund (IMF...   \n",
       "6  Your Excellency and Dear Mr. President-Elect,â€‹...   \n",
       "\n",
       "                                  dependency_parsing  \n",
       "2  [(Hustler, compound, Fund), (Fund, compound, A...  \n",
       "3  [(I, nsubj, had), (have, aux, had), (had, ROOT...  \n",
       "4  [(Kenya, nsubj, signed), (and, cc, Kenya), (th...  \n",
       "5  [(Kenya, nsubj, have), (and, cc, Kenya), (the,...  \n",
       "6  [(Your, poss, Excellency), (Excellency, dep, c...  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply dependency parsing to the 'text' column in the dataset\n",
    "def dependency_parsing(text):\n",
    "    doc = nlp(text)\n",
    "    return [(token.text, token.dep_, token.head.text) for token in doc]\n",
    "\n",
    "# Apply dependency parsing and store in a new column\n",
    "cleaned_tweets['dependency_parsing'] = cleaned_tweets['full_text'].apply(dependency_parsing)\n",
    "\n",
    "\n",
    "cleaned_tweets[['full_text', 'dependency_parsing']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#', 'dep', 'Is'),\n",
       " ('STATEMENT', 'nsubj', 'Is'),\n",
       " ('\\n\\n', 'dep', 'STATEMENT'),\n",
       " ('The', 'det', 'Jurisprudence'),\n",
       " ('Jurisprudence', 'appos', 'STATEMENT'),\n",
       " ('of', 'prep', 'Jurisprudence'),\n",
       " ('Punishment', 'pobj', 'of'),\n",
       " (',', 'punct', 'Jurisprudence'),\n",
       " ('whether', 'mark', 'enforced'),\n",
       " ('enforced', 'advcl', 'Is'),\n",
       " ('by', 'agent', 'enforced'),\n",
       " ('the', 'det', 'State'),\n",
       " ('State', 'pobj', 'by'),\n",
       " (',', 'punct', 'Is'),\n",
       " ('Parents', 'nsubj', 'Is'),\n",
       " ('or', 'cc', 'Parents'),\n",
       " ('Institutions-', 'conj', 'Parents'),\n",
       " ('Is', 'ccomp', 'be'),\n",
       " ('never', 'neg', 'Is'),\n",
       " ('out', 'prep', 'Is'),\n",
       " ('of', 'prep', 'out'),\n",
       " ('Hate', 'pobj', 'of'),\n",
       " ('\\n\\n', 'dep', 'Hate'),\n",
       " ('It', 'nsubjpass', 'Meant'),\n",
       " (\"'s\", 'auxpass', 'Meant'),\n",
       " ('Meant', 'ccomp', 'Is'),\n",
       " ('as', 'prep', 'Meant'),\n",
       " ('a', 'det', 'Deterrent'),\n",
       " ('Deterrent', 'pobj', 'as'),\n",
       " ('and', 'cc', 'Deterrent'),\n",
       " ('Rehabilitation', 'conj', 'Deterrent'),\n",
       " ('\\n\\n', 'dep', 'Rehabilitation'),\n",
       " ('However', 'advmod', 'Is'),\n",
       " (',', 'punct', 'be'),\n",
       " ('Punishment', 'nsubj', 'be'),\n",
       " ('should', 'aux', 'be'),\n",
       " ('be', 'ROOT', 'be'),\n",
       " ('a', 'det', 'consequence'),\n",
       " ('consequence', 'attr', 'be'),\n",
       " ('of', 'prep', 'consequence'),\n",
       " ('an', 'det', 'iniquity'),\n",
       " ('iniquity', 'pobj', 'of'),\n",
       " (',', 'punct', 'iniquity'),\n",
       " ('a', 'det', 'crime'),\n",
       " ('crime', 'appos', 'iniquity'),\n",
       " ('...', 'punct', 'be'),\n",
       " ('In', 'ROOT', 'In'),\n",
       " ('tandem', 'pobj', 'In'),\n",
       " ('with', 'prep', 'tandem'),\n",
       " ('the', 'det', 'deed'),\n",
       " ('deed', 'pobj', 'with'),\n",
       " ('\\n\\n', 'dep', 'deed'),\n",
       " ('But', 'cc', 'In'),\n",
       " ('when', 'advmod', 'https://t.co/DEorjHJorS'),\n",
       " ('a', 'det', 'https://t.co/DEorjHJorS'),\n",
       " ('â€¦', 'punct', 'https://t.co/DEorjHJorS'),\n",
       " ('https://t.co/DEorjHJorS', 'pobj', 'In')]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check dependency parsing in row 8\n",
    "cleaned_tweets['dependency_parsing'].iloc[58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user/name</th>\n",
       "      <th>user/screen_name</th>\n",
       "      <th>user/verified</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Lemmatised</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>dependency_parsing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>Hustler Fund 2nd Anniversary, KICC, Nairobi. h...</td>\n",
       "      <td>[Hustler, Fund, 2nd, Anniversary, ,, KICC, ,, ...</td>\n",
       "      <td>[(Hustler, PROPN), (Fund, PROPN), (2nd, PROPN)...</td>\n",
       "      <td>[(Hustler, compound, Fund), (Fund, compound, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>I have had a fruitful engagement with Retired ...</td>\n",
       "      <td>[I, fruitful, engagement, retired, President, ...</td>\n",
       "      <td>[(I, PRON), (have, AUX), (had, VERB), (a, DET)...</td>\n",
       "      <td>[(I, nsubj, had), (have, aux, had), (had, ROOT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>Kenya and the US signed the Washington-Nairobi...</td>\n",
       "      <td>[Kenya, US, sign, Washington, -, Nairobi, Visi...</td>\n",
       "      <td>[(Kenya, PROPN), (and, CCONJ), (the, DET), (US...</td>\n",
       "      <td>[(Kenya, nsubj, signed), (and, cc, Kenya), (th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>Kenya and the International Monetary Fund (IMF...</td>\n",
       "      <td>[Kenya, International, Monetary, Fund, (, IMF,...</td>\n",
       "      <td>[(Kenya, PROPN), (and, CCONJ), (the, DET), (In...</td>\n",
       "      <td>[(Kenya, nsubj, have), (and, cc, Kenya), (the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>William Samoei Ruto, PhD</td>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>False</td>\n",
       "      <td>Your Excellency and Dear Mr. President-Elect,â€‹...</td>\n",
       "      <td>[your, Excellency, Dear, Mr., President, -, El...</td>\n",
       "      <td>[(Your, PRON), (Excellency, PROPN), (and, CCON...</td>\n",
       "      <td>[(Your, poss, Excellency), (Excellency, dep, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>khalif kairo</td>\n",
       "      <td>KhalifKairo</td>\n",
       "      <td>False</td>\n",
       "      <td>Mm sizimi simu, saa hii niko kwa jam apa Ngara...</td>\n",
       "      <td>[mm, sizimi, simu, ,, saa, hii, niko, kwa, jam...</td>\n",
       "      <td>[(Mm, INTJ), (sizimi, ADJ), (simu, NOUN), (,, ...</td>\n",
       "      <td>[(Mm, compound, simu), (sizimi, amod, simu), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>khalif kairo</td>\n",
       "      <td>KhalifKairo</td>\n",
       "      <td>False</td>\n",
       "      <td>Clearly this is a man who is used to killing, ...</td>\n",
       "      <td>[clearly, man, kill, ,, buy, intimidate, peopl...</td>\n",
       "      <td>[(Clearly, ADV), (this, PRON), (is, AUX), (a, ...</td>\n",
       "      <td>[(Clearly, advmod, is), (this, nsubj, is), (is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>khalif kairo</td>\n",
       "      <td>KhalifKairo</td>\n",
       "      <td>False</td>\n",
       "      <td>Hate to be the NIS/DCI guy assigned to tail me...</td>\n",
       "      <td>[hate, NIS, /, DCI, guy, assign, tail, old, un...</td>\n",
       "      <td>[(Hate, VERB), (to, PART), (be, AUX), (the, DE...</td>\n",
       "      <td>[(Hate, ROOT, Hate), (to, aux, be), (be, xcomp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>khalif kairo</td>\n",
       "      <td>KhalifKairo</td>\n",
       "      <td>False</td>\n",
       "      <td>We are formatting this country.\\nGoing forward...</td>\n",
       "      <td>[we, format, country, ., \\n, go, forward, ,, s...</td>\n",
       "      <td>[(We, PRON), (are, AUX), (formatting, VERB), (...</td>\n",
       "      <td>[(We, nsubj, formatting), (are, aux, formattin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>khalif kairo</td>\n",
       "      <td>KhalifKairo</td>\n",
       "      <td>False</td>\n",
       "      <td>GIVE YOUR TWITTER ACCOUNT TO PEOPLE YOU TRUST....</td>\n",
       "      <td>[give, your, twitter, account, to, PEOPLE, you...</td>\n",
       "      <td>[(GIVE, VERB), (YOUR, PRON), (TWITTER, NOUN), ...</td>\n",
       "      <td>[(GIVE, ROOT, GIVE), (YOUR, poss, ACCOUNT), (T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    user/name user/screen_name user/verified  \\\n",
       "2    William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "3    William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "4    William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "5    William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "6    William Samoei Ruto, PhD     WilliamsRuto         False   \n",
       "..                        ...              ...           ...   \n",
       "156              khalif kairo      KhalifKairo         False   \n",
       "157              khalif kairo      KhalifKairo         False   \n",
       "158              khalif kairo      KhalifKairo         False   \n",
       "159              khalif kairo      KhalifKairo         False   \n",
       "160              khalif kairo      KhalifKairo         False   \n",
       "\n",
       "                                             full_text  \\\n",
       "2    Hustler Fund 2nd Anniversary, KICC, Nairobi. h...   \n",
       "3    I have had a fruitful engagement with Retired ...   \n",
       "4    Kenya and the US signed the Washington-Nairobi...   \n",
       "5    Kenya and the International Monetary Fund (IMF...   \n",
       "6    Your Excellency and Dear Mr. President-Elect,â€‹...   \n",
       "..                                                 ...   \n",
       "156  Mm sizimi simu, saa hii niko kwa jam apa Ngara...   \n",
       "157  Clearly this is a man who is used to killing, ...   \n",
       "158  Hate to be the NIS/DCI guy assigned to tail me...   \n",
       "159  We are formatting this country.\\nGoing forward...   \n",
       "160  GIVE YOUR TWITTER ACCOUNT TO PEOPLE YOU TRUST....   \n",
       "\n",
       "                                            Lemmatised  \\\n",
       "2    [Hustler, Fund, 2nd, Anniversary, ,, KICC, ,, ...   \n",
       "3    [I, fruitful, engagement, retired, President, ...   \n",
       "4    [Kenya, US, sign, Washington, -, Nairobi, Visi...   \n",
       "5    [Kenya, International, Monetary, Fund, (, IMF,...   \n",
       "6    [your, Excellency, Dear, Mr., President, -, El...   \n",
       "..                                                 ...   \n",
       "156  [mm, sizimi, simu, ,, saa, hii, niko, kwa, jam...   \n",
       "157  [clearly, man, kill, ,, buy, intimidate, peopl...   \n",
       "158  [hate, NIS, /, DCI, guy, assign, tail, old, un...   \n",
       "159  [we, format, country, ., \\n, go, forward, ,, s...   \n",
       "160  [give, your, twitter, account, to, PEOPLE, you...   \n",
       "\n",
       "                                              pos_tags  \\\n",
       "2    [(Hustler, PROPN), (Fund, PROPN), (2nd, PROPN)...   \n",
       "3    [(I, PRON), (have, AUX), (had, VERB), (a, DET)...   \n",
       "4    [(Kenya, PROPN), (and, CCONJ), (the, DET), (US...   \n",
       "5    [(Kenya, PROPN), (and, CCONJ), (the, DET), (In...   \n",
       "6    [(Your, PRON), (Excellency, PROPN), (and, CCON...   \n",
       "..                                                 ...   \n",
       "156  [(Mm, INTJ), (sizimi, ADJ), (simu, NOUN), (,, ...   \n",
       "157  [(Clearly, ADV), (this, PRON), (is, AUX), (a, ...   \n",
       "158  [(Hate, VERB), (to, PART), (be, AUX), (the, DE...   \n",
       "159  [(We, PRON), (are, AUX), (formatting, VERB), (...   \n",
       "160  [(GIVE, VERB), (YOUR, PRON), (TWITTER, NOUN), ...   \n",
       "\n",
       "                                    dependency_parsing  \n",
       "2    [(Hustler, compound, Fund), (Fund, compound, A...  \n",
       "3    [(I, nsubj, had), (have, aux, had), (had, ROOT...  \n",
       "4    [(Kenya, nsubj, signed), (and, cc, Kenya), (th...  \n",
       "5    [(Kenya, nsubj, have), (and, cc, Kenya), (the,...  \n",
       "6    [(Your, poss, Excellency), (Excellency, dep, c...  \n",
       "..                                                 ...  \n",
       "156  [(Mm, compound, simu), (sizimi, amod, simu), (...  \n",
       "157  [(Clearly, advmod, is), (this, nsubj, is), (is...  \n",
       "158  [(Hate, ROOT, Hate), (to, aux, be), (be, xcomp...  \n",
       "159  [(We, nsubj, formatting), (are, aux, formattin...  \n",
       "160  [(GIVE, ROOT, GIVE), (YOUR, poss, ACCOUNT), (T...  \n",
       "\n",
       "[158 rows x 7 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rono\\AppData\\Local\\Temp\\ipykernel_12324\\2122901585.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['sentiment'] = data['full_text'].apply(calculate_sentiment)\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "data = cleaned_tweets\n",
    "\n",
    "# Perform Sentiment Analysis\n",
    "def calculate_sentiment(text):\n",
    "    try:\n",
    "        return TextBlob(text).sentiment.polarity  # Returns a value between -1 (negative) and 1 (positive)\n",
    "    except:\n",
    "        return None  \n",
    "\n",
    "# Add Sentiment Scores\n",
    "data['sentiment'] = data['full_text'].apply(calculate_sentiment)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Average Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FabrizioRomano</td>\n",
       "      <td>0.126191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>0.095833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honeyfarsafi</td>\n",
       "      <td>0.067721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ombachi13</td>\n",
       "      <td>0.019638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amerix</td>\n",
       "      <td>0.015290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KhalifKairo</td>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>polo_kimanii</td>\n",
       "      <td>-0.051024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AokoOtieno_</td>\n",
       "      <td>-0.100829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             User  Average Sentiment\n",
       "1  FabrizioRomano           0.126191\n",
       "4    WilliamsRuto           0.095833\n",
       "2    Honeyfarsafi           0.067721\n",
       "6       ombachi13           0.019638\n",
       "5          amerix           0.015290\n",
       "3     KhalifKairo           0.000372\n",
       "7    polo_kimanii          -0.051024\n",
       "0     AokoOtieno_          -0.100829"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by User and Calculate Average Sentiment\n",
    "average_sentiment = data.groupby('user/screen_name')['sentiment'].mean().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "average_sentiment.columns = ['User', 'Average Sentiment']\n",
    "average_sentiment_sorted=average_sentiment.sort_values(by='Average Sentiment', ascending=False)\n",
    "\n",
    "average_sentiment_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Sentiment Score: 0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rono\\AppData\\Local\\Temp\\ipykernel_12324\\1262892941.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['sentiment'] = data['full_text'].apply(calculate_sentiment)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform Sentiment Analysis\n",
    "def calculate_sentiment(text):\n",
    "    try:\n",
    "        return TextBlob(text).sentiment.polarity  \n",
    "    except:\n",
    "        return None  \n",
    "# Add Sentiment Scores\n",
    "data['sentiment'] = data['full_text'].apply(calculate_sentiment)\n",
    "\n",
    "# Calculate Overall Sentiment Score\n",
    "overall_sentiment_score = data['sentiment'].mean()\n",
    "\n",
    "# Output the Result\n",
    "print(f\"Overall Sentiment Score: {overall_sentiment_score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rono\\AppData\\Local\\Temp\\ipykernel_12324\\315544340.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_tweets['key_words'] = cleaned_tweets['full_text'].apply(extract_key_words)\n",
      "C:\\Users\\Rono\\AppData\\Local\\Temp\\ipykernel_12324\\315544340.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_tweets['sentiment'] = cleaned_tweets['key_words'].apply(calculate_sentiment)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load SpaCy model for dependency parsing\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function for extracting key words using dependency parsing\n",
    "def extract_key_words(text):\n",
    "    doc = nlp(text)\n",
    "    key_words = []\n",
    "    for token in doc:\n",
    "        # Extract nouns, verbs, and adjectives as key words\n",
    "        if token.pos_ in ['NOUN', 'VERB', 'ADJ']:\n",
    "            key_words.append(token.text)\n",
    "    return ' '.join(key_words)  # Return as a string to apply sentiment analysis\n",
    "\n",
    "# Apply dependency parsing to extract key words\n",
    "cleaned_tweets['key_words'] = cleaned_tweets['full_text'].apply(extract_key_words)\n",
    "\n",
    "# Function to calculate sentiment score using TextBlob\n",
    "def calculate_sentiment(text):\n",
    "    try:\n",
    "        return TextBlob(text).sentiment.polarity  \n",
    "    except:\n",
    "        return None  \n",
    "\n",
    "# Perform sentiment analysis on extracted key words\n",
    "cleaned_tweets['sentiment'] = cleaned_tweets['key_words'].apply(calculate_sentiment)\n",
    "\n",
    "# Calculate overall sentiment score for the entire data\n",
    "overall_sentiment_score = cleaned_tweets['sentiment'].mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Sentiment Score for Key Words: 0.039\n"
     ]
    }
   ],
   "source": [
    "# Output the result\n",
    "print(f\"Overall Sentiment Score for Key Words: {overall_sentiment_score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user/screen_name</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AokoOtieno_</td>\n",
       "      <td>-0.026771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FabrizioRomano</td>\n",
       "      <td>0.112867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honeyfarsafi</td>\n",
       "      <td>0.068750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KhalifKairo</td>\n",
       "      <td>0.004157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WilliamsRuto</td>\n",
       "      <td>0.119699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amerix</td>\n",
       "      <td>0.003561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ombachi13</td>\n",
       "      <td>0.017020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>polo_kimanii</td>\n",
       "      <td>0.022083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user/screen_name  sentiment\n",
       "0      AokoOtieno_  -0.026771\n",
       "1   FabrizioRomano   0.112867\n",
       "2     Honeyfarsafi   0.068750\n",
       "3      KhalifKairo   0.004157\n",
       "4     WilliamsRuto   0.119699\n",
       "5           amerix   0.003561\n",
       "6        ombachi13   0.017020\n",
       "7     polo_kimanii   0.022083"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Group by user/name and calculate the mean sentiment for each user\n",
    "user_sentiment = cleaned_tweets.groupby('user/screen_name')['sentiment'].mean().reset_index()\n",
    "sorted_sentiment=user_sentiment.sort_values(by='sentiment', ascending=False)\n",
    "# Display the result\n",
    "(user_sentiment)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
